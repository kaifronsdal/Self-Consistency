{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8b0c2f73e1646c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T01:29:35.162493Z",
     "start_time": "2024-02-27T01:29:34.801379Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lfs/hyperturing1/0/kaif/miniforge/envs/sc/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba13fe1-54fd-499f-9e9c-fdc0e05f25fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T22:02:55.854265Z",
     "start_time": "2024-02-27T22:02:53.600334Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,6,7,8\"\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "from dataset import load_datasets, BOXED_ANSWERS_DATASETS, get_boxed_answer\n",
    "from latex_formater import latex_deformat\n",
    "from prompt import generate_nshot_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8c78462800a7ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T21:52:31.938845Z",
     "start_time": "2024-02-27T21:52:31.612023Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "??SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ddcfe5-fa56-4779-9025-ca7e1a390ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T22:03:35.753789Z",
     "start_time": "2024-02-27T22:02:56.739673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-27 14:02:56 config.py:413] Custom all-reduce kernels are temporarily disabled due to stability issues. We will re-enable them once the issues are resolved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 14:02:58,955\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-27 14:03:00 llm_engine.py:79] Initializing an LLM engine with config: model='meta-llama/Llama-2-7b-hf', tokenizer='meta-llama/Llama-2-7b-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=4, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n",
      "\u001b[36m(RayWorkerVllm pid=1272414)\u001b[0m INFO 02-27 14:03:14 weight_utils.py:163] Using model weights format ['*.safetensors']\n",
      "INFO 02-27 14:03:14 weight_utils.py:163] Using model weights format ['*.safetensors']\n",
      "INFO 02-27 14:03:18 llm_engine.py:337] # GPU blocks: 18453, # CPU blocks: 2048\n",
      "INFO 02-27 14:03:20 model_runner.py:676] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-27 14:03:20 model_runner.py:680] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=1272132)\u001b[0m INFO 02-27 14:03:20 model_runner.py:676] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=1272132)\u001b[0m INFO 02-27 14:03:20 model_runner.py:680] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=1272132)\u001b[0m INFO 02-27 14:03:14 weight_utils.py:163] Using model weights format ['*.safetensors']\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayWorkerVllm pid=1272414)\u001b[0m INFO 02-27 14:03:35 model_runner.py:748] Graph capturing finished in 15 secs.\n",
      "\u001b[36m(RayWorkerVllm pid=1272622)\u001b[0m INFO 02-27 14:03:20 model_runner.py:676] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerVllm pid=1272622)\u001b[0m INFO 02-27 14:03:20 model_runner.py:680] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "INFO 02-27 14:03:35 model_runner.py:748] Graph capturing finished in 15 secs.\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=1028)\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "llm = LLM(model=model_name, trust_remote_code=True, tensor_parallel_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ce9336-d3e6-4ad7-940f-46b11d4e8e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T22:06:20.342781Z",
     "start_time": "2024-02-27T22:06:14.429068Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "datasets = load_datasets(BOXED_ANSWERS_DATASETS);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610b78b-7416-4d96-8a9b-0fcea7ddda10",
   "metadata": {},
   "source": [
    "A board game spinner is divided into three parts labeled $A$, $B$  and $C$.\n",
    "The probability of the spinner landing on $A$ is $\\\\frac{1}{3}$ and the\n",
    "probability of the spinner landing on $B$ is $\\\\frac{5}{12}$.  What is\n",
    "the probability of the spinner landing on $C$? Express your answer as a\n",
    "common fraction.\n",
    "\n",
    "Solution: The spinner is guaranteed to land on exactly one of the three\n",
    "regions, so we know that the sum of the probabilities of it landing in\n",
    "each region will be 1. If we let the probability of it landing in region\n",
    "$C$ be $x$, we then have the equation $1 = \\\\frac{5}{12}+\\\\frac{1}{3}+x$,\n",
    "from which we have $x=\\\\boxed{\\\\frac{1}{4}}$.\n",
    "\n",
    "Above is a question and correct solution. Propose a place in the solution\n",
    "where a normal student might make a reasoning mistake. Then explain the\n",
    "error beginning with \"Explanation:\".\n",
    "~~\n",
    "The student might make a mistake when summing the probabilities, and more\n",
    "specifically when making the conversion between fractions and whole numbers.\n",
    "\n",
    "Explanation: A common error might involve not correctly accounting for the\n",
    "total probability being 1. For instance, the student might disregard the\n",
    "conversion between different types of fractions. In this case, the student\n",
    "may add the fractions incorrectly, perhaps adding $\\frac{1}{3}$ and\n",
    "$\\frac{5}{12}$ as if they are like fractions, resulting in a incorrect sum\n",
    "of $\\frac{6}{15}$ instead of the correct sum $\\frac{13}{12}$, and\n",
    "subsequently derive an incorrect value for $x$. \n",
    "~~\n",
    "Now construct the students complete response that makes this mistake. Do\n",
    "NOT point out the mistake in the response. Adhere to the original\n",
    "formatting. Begin with \"Solution:\".\n",
    "~~\n",
    "Solution: The spinner is guaranteed to land on exactly one of the three\n",
    "regions, so we know that the sum of the probabilities of it landing in\n",
    "each region will be 1. If we let the probability of it landing in region\n",
    "$C$ be $x$, we then have the equation $1 = \\frac{5}{12}+\\frac{1}{3}+x$. \n",
    "\n",
    "When adding the fractions $\\frac{5}{12}$ and $\\frac{1}{3}$ directly, we\n",
    "get $\\frac{6}{15}$. Subtracting this from 1 gives us $1 - \\frac{6}{15}\n",
    "= \\frac{9}{15}$, which simplifies to $x = \\boxed{\\frac{3}{5}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80593f1308a3f14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T22:06:52.312791Z",
     "start_time": "2024-02-27T22:06:52.306627Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET_MAP = {\n",
    "    'EleutherAI/hendrycks_math_algebra': 'Algebra',\n",
    "    'EleutherAI/hendrycks_math_counting_and_probability': 'Counting and Probability',\n",
    "    'EleutherAI/hendrycks_math_geometry': 'Geometry',\n",
    "    'EleutherAI/hendrycks_math_intermediate_algebra': 'Intermediate Algebra',\n",
    "    'EleutherAI/hendrycks_math_number_theory': 'Number Theory',\n",
    "    'EleutherAI/hendrycks_math_prealgebra': 'Prealgebra',\n",
    "    'EleutherAI/hendrycks_math_precalculus': 'Precalculus',\n",
    "    'gsm8k_main': 'GSM8K'\n",
    "}\n",
    "\n",
    "MODEL_MAP = {\n",
    "    'deepseek-ai/deepseek-math-7b-rl': 'Deepseek-7b-RL',\n",
    "    'deepseek-ai/deepseek-math-7b-instruct': 'Deepseek-7b-Instruct',\n",
    "    'llm-agents/tora-13b-v1.0': 'Tora-13b-v1.0',\n",
    "    'EleutherAI/llemma_7b': 'LLeMMA-7b',\n",
    "    'llm-agents/tora-7b-v1.0': 'Tora-7b-v1.0',\n",
    "    'google/gemma-7b': 'Gemma-7b',\n",
    "    'morph-labs/morph-prover-v0-7b': 'Morph-7b-v0',\n",
    "    'lmsys/vicuna-13b-v1.5': 'Vicuna-13b-v1.5',\n",
    "    'lmsys/vicuna-7b-v1.5': 'Vicuna-7b-v1.5',\n",
    "    'mistralai/Mistral-7B-Instruct-v0.2': 'Mistral-7b-Instruct-v0.2',\n",
    "    'meta-llama/Llama-2-13b-chat-hf': 'Llama-2-13b',\n",
    "    'meta-llama/Llama-2-7b-hf': 'Llama-2-7b'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c432d83787b08f33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T22:06:27.388490Z",
     "start_time": "2024-02-27T22:06:26.922297Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = {DATASET_MAP[dataset['name']]: generate_nshot_prompts(dataset['data']['train'], n=3) for dataset in datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1c292dd7b0376d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T22:06:30.564579Z",
     "start_time": "2024-02-27T22:06:30.550994Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(prompts['Algebra'][1]['question'])\n",
    "# prompt the model for the answers for the question\n",
    "from util import save_output\n",
    "\n",
    "\n",
    "@save_output\n",
    "def generate(dataset, model, sampling_params):\n",
    "    prompts = [p['question'] for p in dataset]\n",
    "    outputs = model.generate(prompts, sampling_params)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d370c26b32444",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-27T22:06:54.268453Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|                                                                 | 0/1741 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path(\"~/generated_predictions\").expanduser()\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "load = True\n",
    "predictions = {\n",
    "    dataset: generate(\n",
    "        prompts, llm, sampling_params, load=load,\n",
    "        output_path=save_dir / f\"{dataset}_{MODEL_MAP[model_name]}_predictions.pkl\"\n",
    "    ) for dataset, prompts in datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a32b234932d21fcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T21:38:28.844263Z",
     "start_time": "2024-02-27T21:38:28.821710Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import get_boxed_answer\n",
    "from latex_formater import latex_deformat\n",
    "\n",
    "\n",
    "def grade(answers: list[str], targets: list[str]) -> list:\n",
    "    return [a == t for a, t in zip(answers, targets)]\n",
    "\n",
    "\n",
    "def grade_predictions(outputs, data):\n",
    "    boxed_predictions = []\n",
    "    for o in outputs:\n",
    "        try:\n",
    "            boxed_predictions.append(latex_deformat(get_boxed_answer(o.outputs[0].text)))\n",
    "        except:\n",
    "            print(get_boxed_answer(o.outputs[0].text))\n",
    "\n",
    "    # boxed_predictions = [latex_deformat(get_boxed_answer(o.outputs[0].text)) for o in outputs]\n",
    "    boxed_answers = [latex_deformat(get_boxed_answer(d)) for d in data]\n",
    "    grades = grade(boxed_predictions, boxed_answers)\n",
    "\n",
    "    return grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ba29985d2299904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T21:47:32.121565Z",
     "start_time": "2024-02-27T21:47:32.109098Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following 4 questions:\n",
      "\n",
      "1. Let \\[f(x) = \\left\\{\n",
      "\\begin{array}{cl} ax+3, &\\text{ if }x>2, \\\\\n",
      "x-5 &\\text{ if } -2 \\le x \\le 2, \\\\\n",
      "2x-b &\\text{ if } x <-2.\n",
      "\\end{array}\n",
      "\\right.\\]Find $a+b$ if the piecewise function is continuous (which means that its graph can be drawn without lifting your pencil from the paper).\n",
      "\n",
      "For the piecewise function to be continuous, the cases must \"meet\" at $2$ and $-2$. For example, $ax+3$ and $x-5$ must be equal when $x=2$. This implies $a(2)+3=2-5$, which we solve to get $2a=-6 \\Rightarrow a=-3$. Similarly, $x-5$ and $2x-b$ must be equal when $x=-2$. Substituting, we get $-2-5=2(-2)-b$, which implies $b=3$. So $a+b=-3+3=\\boxed{0}$.\n",
      "\n",
      "\n",
      "2. A rectangular band formation is a formation with $m$ band members in each of $r$ rows, where $m$ and $r$ are integers. A particular band has less than 100 band members. The director arranges them in a rectangular formation and finds that he has two members left over. If he increases the number of members in each row by 1 and reduces the number of rows by 2, there are exactly enough places in the new formation for each band member. What is the largest number of members the band could have?\n",
      "\n",
      "Let $x$ be the number of band members in each row for the original formation, when two are left over.  Then we can write two equations from the given information: $$rx+2=m$$ $$(r-2)(x+1)=m$$ Setting these equal, we find: $$rx+2=(r-2)(x+1)=rx-2x+r-2$$ $$2=-2x+r-2$$ $$4=r-2x$$ We know that the band has less than 100 members.  Based on the first equation, we must have $rx$ less than 98.  We can guess and check some values of $r$ and $x$ in the last equation.  If $r=18$, then $x=7$, and $rx=126$ which is too big.  If $r=16$, then $x=6$, and $rx=96$, which is less than 98.  Checking back in the second formation, we see that $(16-2)(6+1)=14\\cdot 7=98$ as it should.  This is the best we can do, so the largest number of members the band could have is $\\boxed{98}$.\n",
      "\n",
      "\n",
      "3. What is the degree of the polynomial $(4 +5x^3 +100 +2\\pi x^4 + \\sqrt{10}x^4 +9)$?\n",
      "\n",
      "This polynomial is not written in standard form.  However, we don't need to write it in standard form, nor do we need to pay attention to the coefficients.  We just look for the exponents on $x$.  We have an $x^4$ term and no other term of higher degree, so $\\boxed{4}$ is the degree of the polynomial.\n",
      "\n",
      "\n",
      "4. Evaluate $\\left\\lceil3\\left(6-\\frac12\\right)\\right\\rceil$.\n",
      "\n",
      "\n",
      "To evaluate this expression, we use the order of operations (PEMDAS) as follows:\n",
      "\n",
      "1. Simplify the inside of the parentheses.\n",
      "2. Evaluate the exponent.\n",
      "3. Evaluate the inside of the parentheses.\n",
      "4. Apply the ceiling function.\n",
      "\n",
      "First, simplify the exponent: $6-\\frac12=5-\\frac12=2$. Next, evaluate the inside of the parentheses: $3(2)=6$. Now, we apply the ceiling function. Since $6$ is not a whole number, we round up to $\\boxed{7}$.\n",
      "Firstly, $3\\left(6-\\frac12\\right)=18-1-\\frac12=17-\\frac12$.  Because $0\\le\\frac12<1$, we have $\\left\\lceil17-\\frac12\\right\\rceil=\\boxed{17}$.\n"
     ]
    }
   ],
   "source": [
    "print(predictions['Algebra'][0].prompt)\n",
    "print(predictions['Algebra'][0].outputs[0].text)\n",
    "print(datasets['Algebra'][0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2d71bff147cf592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T21:43:57.383934Z",
     "start_time": "2024-02-27T21:43:57.084387Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grades = {dataset: grade_predictions(predictions[dataset], [p['answer'] for p in data]) for dataset, data in\n",
    "          datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a6bdadaafc3d41c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T21:44:24.792056Z",
     "start_time": "2024-02-27T21:44:24.775684Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Algebra': 0.026421596783457783,\n",
       " 'Counting and Probability': 0.01171875,\n",
       " 'Geometry': 0.0034602076124567475,\n",
       " 'Intermediate Algebra': 0.0030959752321981426,\n",
       " 'Number Theory': 0.023094688221709007,\n",
       " 'Prealgebra': 0.04409317803660566,\n",
       " 'Precalculus': 0.0,\n",
       " 'GSM8K': 0.9925048517700595}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "{dataset: np.mean(grade) for dataset, grade in grades.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e84ac9fd5da8afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T21:35:03.599363Z",
     "start_time": "2024-02-27T21:35:03.019332Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the predictions\n",
    "# for dataset, outputs in predictions.items():\n",
    "#     with open(save_dir / f\"{dataset.replace(' ', '-')}_{MODEL_MAP[model_name]}_predictions.pkl\", \"wb\") as f:\n",
    "#         pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf5d2ab-024e-4889-9e51-1450633a4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompts, model, sampling_params, chat_mode=False):\n",
    "    outputs = llm.generate(prompts, sampling_params)\n",
    "    if chat_mode:\n",
    "        return [prompt + o.outputs[0].text for prompt, o in zip(prompts, outputs)]\n",
    "    else:\n",
    "        return [o.outputs[0].text for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e0cea1-0114-43af-8857-a821bb76d148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████| 1/1 [00:24<00:00, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A board game spinner is divided into three parts labeled $A$, $B$  and $C$.\n",
      "The probability of the spinner landing on $A$ is $\\frac{1}{3}$ and the\n",
      "probability of the spinner landing on $B$ is $\\frac{5}{12}$.  What is\n",
      "the probability of the spinner landing on $C$? Express your answer as a\n",
      "common fraction. Write your final answer as \"\\boxed{...}\".\n",
      "\n",
      "Solution:\n",
      "We want to find the probability of the spinner landing on $C$, which means that it must land on $A$ or $B$ and not on $C$. We can find this by using the formula for conditional probability:\n",
      "\n",
      "P(C) = P(C|A) \\* P(A) + P(C|B) \\* P(B)\n",
      "\n",
      "We know that P(A) = $\\frac{1}{3}$ and P(B) = $\\frac{5}{12}$, so we need to find P(C|A) and P(C|B).\n",
      "\n",
      "P(C|A) means the probability of the spinner landing on $C$ given that it landed on $A$. To find this, we need to know the probability of the spinner landing on $B$ or $C$ given that it landed on $A$. However, we don't have that information, so we will assume that the probabilities are equal. That is, P(B|A) = P(C|A) = $\\frac{1}{3}$.\n",
      "\n",
      "P(C|B) means the probability of the spinner landing on $C$ given that it landed on $B$. We don't have enough information to find this probability, so we will assume that it is equal to the probability of the spinner landing on $C$ in general, which is $\\frac{1}{3}$.\n",
      "\n",
      "Putting it all together, we get:\n",
      "\n",
      "P(C) = $\\frac{1}{3}$ \\* $\\frac{1}{3}$ + $\\frac{1}{3}$ \\* $\\frac{5}{12}$\n",
      "= $\\frac{1}{9}$ + $\\frac{5}{144}$\n",
      "= $\\frac{6}{144}$\n",
      "= $\\frac{3}{72}$\n",
      "= $\\frac{9}{24}$\n",
      "= $\\frac{3}{4}$\n",
      "\n",
      "So, the probability of the spinner landing on $C$ is $\\frac{3}{4}$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"\"\"A board game spinner is divided into three parts labeled $A$, $B$  and $C$.\n",
    "The probability of the spinner landing on $A$ is $\\\\frac{1}{3}$ and the\n",
    "probability of the spinner landing on $B$ is $\\\\frac{5}{12}$.  What is\n",
    "the probability of the spinner landing on $C$? Express your answer as a\n",
    "common fraction. Write your final answer as \"\\\\boxed{...}\".\n",
    "\n",
    "Solution:\n",
    "\"\"\"]\n",
    "# Solution: The spinner is guaranteed to land on exactly one of the three\n",
    "# regions, so we know that the sum of the probabilities of it landing in\n",
    "# each region will be 1. If we let the probability of it landing in region\n",
    "# $C$ be $x$, we then have the equation $1 = \\\\frac{5}{12}+\\\\frac{1}{3}+x$,\n",
    "# from which we have $x=\\\\boxed{\\\\frac{1}{4}}$.\n",
    "\n",
    "# Above is a question and correct solution. What is a mistake someone might make when solving the problem?\n",
    "\n",
    "# Mistake:\"\"\"]\n",
    "outputs = generate(prompts, llm, sampling_params, chat_mode=True)\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4405c2be-c045-4f7d-94c8-4dee1616dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A board game spinner is divided into three parts labeled $A$, $B$  and $C$.\n",
      "The probability of the spinner landing on $A$ is $\\frac{1}{3}$ and the\n",
      "probability of the spinner landing on $B$ is $\\frac{5}{12}$.  What is\n",
      "the probability of the spinner landing on $C$? Express your answer as a\n",
      "common fraction. Write your final answer as \"\\boxed{...}\".\n",
      "\n",
      "Solution:\n",
      "We want to find the probability of the spinner landing on $C$, which means that it must land on $A$ or $B$ and not on $C$. We can find this by using the formula for conditional probability:\n",
      "\n",
      "P(C) = P(C|A) \\* P(A) + P(C|B) \\* P(B)\n",
      "\n",
      "We know that P(A) = $\\frac{1}{3}$ and P(B) = $\\frac{5}{12}$, so we need to find P(C|A) and P(C|B).\n",
      "\n",
      "P(C|A) means the probability of the spinner landing on $C$ given that it landed on $A$. To find this, we need to know the probability of the spinner landing on $B$ or $C$ given that it landed on $A$. However, we don't have that information, so we will assume that the probabilities are equal. That is, P(B|A) = P(C|A) = $\\frac{1}{3}$.\n",
      "\n",
      "P(C|B) means the probability of the spinner landing on $C$ given that it landed on $B$. We don't have enough information to find this probability, so we will assume that it is equal to the probability of the spinner landing on $C$ in general, which is $\\frac{1}{3}$.\n",
      "\n",
      "Putting it all together, we get:\n",
      "\n",
      "P(C) = $\\frac{1}{3}$ \\* $\\frac{1}{3}$ + $\\frac{1}{3}$ \\* $\\frac{5}{12}$\n",
      "= $\\frac{1}{9}$ + $\\frac{5}{144}$\n",
      "= $\\frac{6}{144}$\n",
      "= $\\frac{3}{72}$\n",
      "= $\\frac{9}{24}$\n",
      "= $\\frac{3}{4}$\n",
      "\n",
      "So, the probability of the spinner landing on $C$ is $\\frac{3}{4}$.\n",
      "\n",
      "Are you sure this is correct?\n",
      "Yes, this is correct.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts2 = [o + \"\"\"\n",
    "\n",
    "Are you sure this is correct?\n",
    "\"\"\" for o in outputs]\n",
    "outputs2 = generate(prompts2, llm, sampling_params, chat_mode=True)\n",
    "print(outputs2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80cb88f9-fc73-4882-a54b-9d5d1835330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A board game spinner is divided into three parts labeled $A$, $B$  and $C$.\n",
      "The probability of the spinner landing on $A$ is $\\frac{1}{3}$ and the\n",
      "probability of the spinner landing on $B$ is $\\frac{5}{12}$.  What is\n",
      "the probability of the spinner landing on $C$? Express your answer as a\n",
      "common fraction.\n",
      "\n",
      "Solution: The spinner is guaranteed to land on exactly one of the three\n",
      "regions, so we know that the sum of the probabilities of it landing in\n",
      "each region will be 1. If we let the probability of it landing in region\n",
      "$C$ be $x$, we then have the equation $1 = \\frac{5}{12}+\\frac{1}{3}+x$,\n",
      "from which we have $x=\\boxed{\\frac{1}{4}}$.\n",
      "\n",
      "Above is a question and correct solution. What is a mistake someone might make when solving the problem?\n",
      "\n",
      "Mistake: One possible mistake is assuming that the probabilities of the spinner landing on each of the three regions must be equal, and therefore setting $x=\\frac{1}{3}$. This is incorrect, as the given probabilities for $A$ and $B$ already show that the probabilities are not equal.\n",
      "\n",
      "Now construct a response that makes this mistake followed \n",
      "by a teacher explaining the mistake made. Begin with \"Incorrect Solution:\" \n",
      "and the teacher corrections with \"Teacher Correction:\".\n",
      "\n",
      "Incorrect Solution: \n",
      "To find the probability of the spinner landing on $C$, we can add the probabilities of it landing on $A$ and $B$, since they are the only other options.\n",
      "$$P(\\text{landing on }C) = P(\\text{landing on }A) + P(\\text{landing on }B)$$\n",
      "$$= \\frac{1}{3} + \\frac{5}{12}$$\n",
      "$$= \\frac{6}{12}$$\n",
      "$$= \\frac{1}{2}$$\n",
      "\n",
      "Teacher Correction:\n",
      "While it's true that $A$ and $B$ are the only other options, assuming that the probabilities of the spinner landing on each of the three regions must be equal is incorrect. We are given the specific probabilities for $A$ and $B$, so we should use those values in our calculation.\n",
      "\n",
      "By using the equation $1 = \\frac{5}{12}+\\frac{1}{3}+x$, we can solve for $x$ to find the probability of the spinner landing on $C$.\n",
      "\n",
      "Incorrect Solution:\n",
      "$$P(\\text{landing on }C) = P(\\text{landing on }A) + P(\\text{landing on }B)$$\n",
      "$$= \\frac{1}{3} + \\frac{5}{12}$$\n",
      "$$= \\frac{6}{12}$$\n",
      "$$= \\frac{1}{2}$$\n",
      "\n",
      "Teacher Correction:\n",
      "The correct equation is $1 = \\frac{5}{12}+\\frac{1}{3}+x$, where $x$ represents the probability of the spinner landing on $C$. By solving for $x$, we get $x = \\frac{1}{4}$, which is the correct answer. So, the probability of the spinner landing on $C$ is $\\frac{1}{4}$.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts2 = [o + \"\"\"\n",
    "\n",
    "Now construct a response that makes this mistake followed \n",
    "by a teacher explaining the mistake made. Begin with \"Incorrect Solution:\" \n",
    "and the teacher corrections with \"Teacher Correction:\".\n",
    "\n",
    "Incorrect Solution: \"\"\" for o in outputs]\n",
    "outputs2 = generate(prompts2, llm, sampling_params, chat_mode=True)\n",
    "print(outputs2[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
